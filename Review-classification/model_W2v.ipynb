{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9f272e",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/sudhanshu2198/processed-data-credit-score/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb5cb52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\YANGZH~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.028 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "C:\\Users\\YANGZH~1\\AppData\\Local\\Temp/ipykernel_23284/2839552769.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.cut[i] = [w for w in jieba.cut(df.txt[i]) if w not in list(stop_word.w)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>标题</th>\n",
       "      <th>类型</th>\n",
       "      <th>txt</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>西安秦岭野生动物园</td>\n",
       "      <td>1</td>\n",
       "      <td>领孩子去玩的，孩子看到了许多动物非常高兴，以后会经常领孩子来玩的，还有马戏表演和海狮的表演孩...</td>\n",
       "      <td>[领, 动物, 非常高兴, 领, 马戏表演, 海狮, 表演, 喜欢, 逛, 动物园, 满意]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>秦始皇帝陵博物院（兵马俑）</td>\n",
       "      <td>0</td>\n",
       "      <td>千里纵横，气吞山河。而最动人之处却是每y形象、表情下的秦时故事，近看非常生动，不得不赞服始皇...</td>\n",
       "      <td>[千里, 纵横, 气吞山河, 动人, 处, 却是, y, 形象, 表情, 秦时, 故事, 近...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>秦始皇帝陵博物院（兵马俑）</td>\n",
       "      <td>0</td>\n",
       "      <td>早点去，没那么多人，携程上订好票，拿身份证就进去，方便的很，市区到那里要近1小时车程，计划好...</td>\n",
       "      <td>[早点, 多人, 携程, 订好, 票, 身份证, 市区, 要近, 1, 小时, 车程, 计划...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>黄帝陵</td>\n",
       "      <td>0</td>\n",
       "      <td>华人必去的地方，但周边环境较差，配套服务设施也没跟上。黄陵县加油！</td>\n",
       "      <td>[华人, 必去, 周边环境, 较差, 配套, 服务设施, 跟上, 黄陵县, 加油]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>安康瀛湖生态旅游区</td>\n",
       "      <td>1</td>\n",
       "      <td>第二次来了，这次的湖水涨了，据说涨了50米。确实是看到和以前不一样了。 门票和船票加起来一共...</td>\n",
       "      <td>[第二次, 湖水, 涨, 涨, 50, 米, 确实,  , 船票, 加, 一共, 80, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              标题  类型                                                txt  \\\n",
       "0      西安秦岭野生动物园   1  领孩子去玩的，孩子看到了许多动物非常高兴，以后会经常领孩子来玩的，还有马戏表演和海狮的表演孩...   \n",
       "1  秦始皇帝陵博物院（兵马俑）   0  千里纵横，气吞山河。而最动人之处却是每y形象、表情下的秦时故事，近看非常生动，不得不赞服始皇...   \n",
       "2  秦始皇帝陵博物院（兵马俑）   0  早点去，没那么多人，携程上订好票，拿身份证就进去，方便的很，市区到那里要近1小时车程，计划好...   \n",
       "3            黄帝陵   0                  华人必去的地方，但周边环境较差，配套服务设施也没跟上。黄陵县加油！   \n",
       "4      安康瀛湖生态旅游区   1  第二次来了，这次的湖水涨了，据说涨了50米。确实是看到和以前不一样了。 门票和船票加起来一共...   \n",
       "\n",
       "                                                 cut  \n",
       "0     [领, 动物, 非常高兴, 领, 马戏表演, 海狮, 表演, 喜欢, 逛, 动物园, 满意]  \n",
       "1  [千里, 纵横, 气吞山河, 动人, 处, 却是, y, 形象, 表情, 秦时, 故事, 近...  \n",
       "2  [早点, 多人, 携程, 订好, 票, 身份证, 市区, 要近, 1, 小时, 车程, 计划...  \n",
       "3          [华人, 必去, 周边环境, 较差, 配套, 服务设施, 跟上, 黄陵县, 加油]  \n",
       "4  [第二次, 湖水, 涨, 涨, 50, 米, 确实,  , 船票, 加, 一共, 80, 1...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "com = pd.read_csv('景点.csv')\n",
    "com = com.drop(['标题链接','图片','bookbtn1','评分','rate','add','图片1','标记','时间'],axis=1)\n",
    "com=pd.concat([com[com['类型']=='历史人文'],com[com['类型']=='自然生态']],axis=0)\n",
    "com.rename(columns={'描述':'txt'},inplace=True)\n",
    "com = com.dropna().reset_index().drop('index',axis=1)\n",
    "\n",
    "mapping = {'历史人文':0,'自然生态':1}\n",
    "com['类型'] = com['类型'].map(mapping)\n",
    "\n",
    "import jieba\n",
    "stop_word = pd.read_csv('停用词.csv',names=['w'],sep='\\t',encoding='utf-8')\n",
    "\n",
    "df=pd.concat([com[com['类型']==0].sample(n=10000),com[com['类型']==1].sample(n=10000)],axis=0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df = df.reset_index().drop('index',axis=1)\n",
    "\n",
    "#这样可以成功\n",
    "df['cut'] = df.txt.apply(jieba.lcut)\n",
    "for i in range(len(df.txt)):\n",
    "    df.cut[i] = [w for w in jieba.cut(df.txt[i]) if w not in list(stop_word.w)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f021410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1f39b5b43a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "n_dim = 300 # 指定向量维度，大样本量时300~500较好\n",
    "\n",
    "w2vmodel = Word2Vec(vector_size = n_dim, min_count = 10) # size改为vector_size\n",
    "w2vmodel.build_vocab(df.cut) # 生成词表\n",
    "w2vmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8981fe19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1f39b5b44c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在评论训练集上建模（大数据集时可能会花费几分钟）\n",
    "# 本例消耗内存较少 100次 40s\n",
    "w2vmodel.train(df.txt,total_examples = w2vmodel.corpus_count, epochs = 100)\n",
    "w2vmodel.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94203a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel.wv.save_word2vec_format('word2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f41022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看生成的特征矩阵\n",
    "import numpy as np\n",
    "\n",
    "# 假设文本数据为text_data，其中每个元素代表一个文本样本\n",
    "feature_matrix = np.zeros((len(df.cut), n_dim))\n",
    "\n",
    "for i,text in enumerate(df.cut):\n",
    "    #print(i)\n",
    "    for j,word in enumerate(text):\n",
    "        if(j<300):\n",
    "            try:\n",
    "                feature_matrix[i]+= w2vmodel.wv[word]\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a76a1d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_matrix\n",
    "y = df['类型']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47583ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>类型</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.444902</td>\n",
       "      <td>1.443579</td>\n",
       "      <td>-5.012238</td>\n",
       "      <td>-3.705452</td>\n",
       "      <td>-0.051508</td>\n",
       "      <td>-2.060765</td>\n",
       "      <td>0.183342</td>\n",
       "      <td>2.727056</td>\n",
       "      <td>0.542888</td>\n",
       "      <td>-2.161844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008649</td>\n",
       "      <td>-3.148773</td>\n",
       "      <td>2.016396</td>\n",
       "      <td>2.274120</td>\n",
       "      <td>0.100440</td>\n",
       "      <td>3.657988</td>\n",
       "      <td>-7.172443</td>\n",
       "      <td>-1.453168</td>\n",
       "      <td>0.851038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.312074</td>\n",
       "      <td>-2.520205</td>\n",
       "      <td>-1.875270</td>\n",
       "      <td>-0.104776</td>\n",
       "      <td>1.286043</td>\n",
       "      <td>0.903555</td>\n",
       "      <td>-0.769248</td>\n",
       "      <td>-1.407261</td>\n",
       "      <td>-1.127001</td>\n",
       "      <td>-1.009300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261822</td>\n",
       "      <td>1.618133</td>\n",
       "      <td>-0.261719</td>\n",
       "      <td>0.447576</td>\n",
       "      <td>0.187161</td>\n",
       "      <td>-0.198379</td>\n",
       "      <td>0.391757</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>-0.920236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.055930</td>\n",
       "      <td>-1.490472</td>\n",
       "      <td>-5.313193</td>\n",
       "      <td>2.226089</td>\n",
       "      <td>-0.042387</td>\n",
       "      <td>0.860641</td>\n",
       "      <td>0.843539</td>\n",
       "      <td>-0.069845</td>\n",
       "      <td>-1.687149</td>\n",
       "      <td>0.560519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140994</td>\n",
       "      <td>2.067355</td>\n",
       "      <td>1.443887</td>\n",
       "      <td>-0.809261</td>\n",
       "      <td>0.593249</td>\n",
       "      <td>0.052857</td>\n",
       "      <td>-3.079727</td>\n",
       "      <td>-1.438631</td>\n",
       "      <td>0.879639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005421</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002766</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>-0.001438</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>-0.004811</td>\n",
       "      <td>-0.003774</td>\n",
       "      <td>-0.008551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.898982</td>\n",
       "      <td>-6.278417</td>\n",
       "      <td>-12.074805</td>\n",
       "      <td>-1.256002</td>\n",
       "      <td>-1.618913</td>\n",
       "      <td>-5.862595</td>\n",
       "      <td>-2.618814</td>\n",
       "      <td>-3.760682</td>\n",
       "      <td>-3.231957</td>\n",
       "      <td>0.918449</td>\n",
       "      <td>...</td>\n",
       "      <td>5.093760</td>\n",
       "      <td>6.097307</td>\n",
       "      <td>-2.602517</td>\n",
       "      <td>2.566232</td>\n",
       "      <td>1.398698</td>\n",
       "      <td>-2.747606</td>\n",
       "      <td>-1.706993</td>\n",
       "      <td>-1.373010</td>\n",
       "      <td>3.289517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>-5.602198</td>\n",
       "      <td>-4.579727</td>\n",
       "      <td>-7.356030</td>\n",
       "      <td>3.695037</td>\n",
       "      <td>1.182230</td>\n",
       "      <td>0.738100</td>\n",
       "      <td>-2.852778</td>\n",
       "      <td>-0.118087</td>\n",
       "      <td>-2.821763</td>\n",
       "      <td>-0.893304</td>\n",
       "      <td>...</td>\n",
       "      <td>2.260461</td>\n",
       "      <td>4.699440</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.826305</td>\n",
       "      <td>-0.925024</td>\n",
       "      <td>2.075049</td>\n",
       "      <td>-4.329169</td>\n",
       "      <td>-2.394764</td>\n",
       "      <td>0.332104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>-0.001107</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>-0.003459</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>-0.003274</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007113</td>\n",
       "      <td>-0.004385</td>\n",
       "      <td>-0.008595</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>-0.000606</td>\n",
       "      <td>-0.004498</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>-0.002171</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>-0.001649</td>\n",
       "      <td>-0.001796</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>-0.002070</td>\n",
       "      <td>-0.000352</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.007261</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>-0.006400</td>\n",
       "      <td>-0.005533</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004272</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>-0.014856</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>-0.014899</td>\n",
       "      <td>-0.011553</td>\n",
       "      <td>-0.009334</td>\n",
       "      <td>-0.009698</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>-0.007496</td>\n",
       "      <td>-0.003240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>-0.010036</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>-0.003686</td>\n",
       "      <td>-0.006653</td>\n",
       "      <td>-0.009743</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1          2         3         4         5         6  \\\n",
       "0     -0.444902  1.443579  -5.012238 -3.705452 -0.051508 -2.060765  0.183342   \n",
       "1     -1.312074 -2.520205  -1.875270 -0.104776  1.286043  0.903555 -0.769248   \n",
       "2     -5.055930 -1.490472  -5.313193  2.226089 -0.042387  0.860641  0.843539   \n",
       "3     -0.005421  0.003225   0.008065  0.002038  0.000045  0.003867  0.002511   \n",
       "4     -5.898982 -6.278417 -12.074805 -1.256002 -1.618913 -5.862595 -2.618814   \n",
       "...         ...       ...        ...       ...       ...       ...       ...   \n",
       "19995 -5.602198 -4.579727  -7.356030  3.695037  1.182230  0.738100 -2.852778   \n",
       "19996 -0.001107  0.001026   0.002040 -0.003459 -0.002136  0.005173 -0.003274   \n",
       "19997  0.000223  0.002163   0.001957 -0.000059  0.000793 -0.002171 -0.003120   \n",
       "19998  0.007261 -0.000233   0.004854  0.001596 -0.006400 -0.005533 -0.000221   \n",
       "19999  0.003578  0.013950  -0.014899 -0.011553 -0.009334 -0.009698  0.009061   \n",
       "\n",
       "              7         8         9  ...       291       292       293  \\\n",
       "0      2.727056  0.542888 -2.161844  ... -0.008649 -3.148773  2.016396   \n",
       "1     -1.407261 -1.127001 -1.009300  ...  0.261822  1.618133 -0.261719   \n",
       "2     -0.069845 -1.687149  0.560519  ...  0.140994  2.067355  1.443887   \n",
       "3      0.001687  0.000709  0.006773  ... -0.002766  0.003305 -0.001438   \n",
       "4     -3.760682 -3.231957  0.918449  ...  5.093760  6.097307 -2.602517   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19995 -0.118087 -2.821763 -0.893304  ...  2.260461  4.699440  0.012579   \n",
       "19996  0.003468  0.007142  0.002793  ... -0.007113 -0.004385 -0.008595   \n",
       "19997 -0.001649 -0.001796  0.000196  ...  0.000397  0.002974  0.002138   \n",
       "19998  0.002154 -0.000289  0.003252  ... -0.004272  0.001932 -0.014856   \n",
       "19999  0.013666 -0.007496 -0.003240  ...  0.004383 -0.010036  0.009166   \n",
       "\n",
       "            294       295       296       297       298       299  类型  \n",
       "0      2.274120  0.100440  3.657988 -7.172443 -1.453168  0.851038   1  \n",
       "1      0.447576  0.187161 -0.198379  0.391757  0.019246 -0.920236   0  \n",
       "2     -0.809261  0.593249  0.052857 -3.079727 -1.438631  0.879639   0  \n",
       "3     -0.000651  0.005022  0.005923 -0.004811 -0.003774 -0.008551   0  \n",
       "4      2.566232  1.398698 -2.747606 -1.706993 -1.373010  3.289517   1  \n",
       "...         ...       ...       ...       ...       ...       ...  ..  \n",
       "19995  0.826305 -0.925024  2.075049 -4.329169 -2.394764  0.332104   1  \n",
       "19996  0.002861  0.001280 -0.000606 -0.004498 -0.003430  0.001951   0  \n",
       "19997 -0.000480 -0.002070 -0.000352  0.002425  0.002494 -0.001344   0  \n",
       "19998  0.002005  0.004452  0.006575 -0.000943 -0.002223  0.007716   1  \n",
       "19999  0.000516 -0.002549 -0.003686 -0.006653 -0.009743 -0.013618   1  \n",
       "\n",
       "[20000 rows x 301 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.concat([pd.DataFrame(X),y],axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a112e2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>类型</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42625</td>\n",
       "      <td>42625</td>\n",
       "      <td>42625</td>\n",
       "      <td>42625</td>\n",
       "      <td>42625</td>\n",
       "      <td>42625</td>\n",
       "      <td>42625</td>\n",
       "      <td>42625</td>\n",
       "      <td>42625</td>\n",
       "      <td>42625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13977</td>\n",
       "      <td>13977</td>\n",
       "      <td>13977</td>\n",
       "      <td>13977</td>\n",
       "      <td>13977</td>\n",
       "      <td>13977</td>\n",
       "      <td>13977</td>\n",
       "      <td>13977</td>\n",
       "      <td>13977</td>\n",
       "      <td>13977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9\n",
       "类型                                                                      \n",
       "0   42625  42625  42625  42625  42625  42625  42625  42625  42625  42625\n",
       "1   13977  13977  13977  13977  13977  13977  13977  13977  13977  13977"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(by='类型').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3800528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间:60751.35827064514毫秒\n",
      "   0     1     2     3     4     5     6     7     8     9     ...  5990  \\\n",
      "0     1     0     1     0     1     1     0     0     0     0  ...     0   \n",
      "1     1     1     1     0     1     1     0     0     0     1  ...     0   \n",
      "\n",
      "   5991  5992  5993  5994  5995  5996  5997  5998  5999  \n",
      "0     1     0     0     1     0     0     0     0     0  \n",
      "1     1     1     1     0     1     0     1     1     0  \n",
      "\n",
      "[2 rows x 6000 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "#训练初步模型\n",
    "model = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "            decision_function_shape='ovr',degree=3, gamma='auto', kernel='rbf',\n",
    "            max_iter=-1, probability=False, random_state=None, shrinking=True,tol=0.001, verbose=False)\n",
    "\n",
    "T1 = time.time()\n",
    "model.fit(X_train,Y_train)\n",
    "T2 = time.time()\n",
    "\n",
    "print('训练时间:%s毫秒' % ((T2 - T1)*1000))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(pd.DataFrame([predictions,Y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9da58a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6183333333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,predictions)        # 0.9298245614035088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef6fa31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为： 0.6183333333333333\n",
      "精确率为： 0.6227314654967512\n",
      "召回率为： 0.6183333333333333\n",
      "F1值为： 0.6183333333333333\n",
      "Cohen’s Kappa系数为： 0.2339729751909827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, \\\n",
    "recall_score,f1_score,cohen_kappa_score\n",
    " \n",
    "print('准确率为：', \n",
    "accuracy_score(Y_test,predictions))      \n",
    "print('精确率为：',\n",
    "      precision_score(Y_test,predictions,average='weighted'))\n",
    "print('召回率为：',\n",
    "      recall_score(Y_test,predictions,average='weighted'))\n",
    "print('F1值为：',\n",
    "      f1_score(Y_test,predictions,average='micro'))\n",
    "print('Cohen’s Kappa系数为：',\n",
    "      cohen_kappa_score(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04bbc30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2936"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4744dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09b24381",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\YANGZH~1\\AppData\\Local\\Temp/ipykernel_24084/1645183296.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvm_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\YANGZH~1\\AppData\\Local\\Temp/ipykernel_24084/1645183296.py\u001b[0m in \u001b[0;36msvm_cross_validation\u001b[1;34m(X_train, Y_train)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gamma'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mbest_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpara\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#交叉验证\n",
    "def svm_cross_validation(X_train,Y_train):    \n",
    "    from sklearn.model_selection import GridSearchCV    \n",
    "    from sklearn.svm import SVC    \n",
    "    model = SVC(kernel='rbf', probability=True)    \n",
    "    param_grid = {'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}    \n",
    "    grid_search = GridSearchCV(model, param_grid, n_jobs = 8, verbose=1)    \n",
    "    grid_search.fit(X_train,Y_train)    \n",
    "    best_parameters = grid_search.best_estimator_.get_params()    \n",
    "    for para, val in list(best_parameters.items()):    \n",
    "        print(para, val)    \n",
    "    model = SVC(kernel='rbf', C=best_parameters['C'], gamma=best_parameters['gamma'], probability=True)    \n",
    "    model.fit(X_train,Y_train)    \n",
    "    return model\n",
    "\n",
    "model=svm_cross_validation(X_train,Y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "print(accuracy_score(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef21ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间: 8.79863452911377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6041666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=3) # 初始化\n",
    "\n",
    "T1 = time.time()\n",
    "clf = clf.fit(X_train,Y_train) # 拟合\n",
    "T2 = time.time()\n",
    "print('训练时间:',T2-T1)\n",
    "score_ = clf.score(X_test, Y_test) # 验证集查看得分，这个得分好像就是分类的准确率\n",
    "\n",
    "# 可以输入数据送到训练好的模型里，输出预测的类\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#评价\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,y_pred)        # 0.9298245614035088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa2f9192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精确率为： 0.604117698561601\n",
      "召回率为： 0.6041666666666666\n",
      "F1值为： 0.6041666666666666\n",
      "Cohen’s Kappa系数为： 0.20802974473548186\n"
     ]
    }
   ],
   "source": [
    "print('精确率为：',\n",
    "      precision_score(Y_test,y_pred,average='weighted'))\n",
    "print('召回率为：',\n",
    "      recall_score(Y_test,y_pred,average='weighted'))\n",
    "print('F1值为：',\n",
    "      f1_score(Y_test,y_pred,average='micro'))\n",
    "print('Cohen’s Kappa系数为：',\n",
    "      cohen_kappa_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33dd255f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7891428571428571\n",
      "Test accuracy: 0.6156666666666667\n",
      "Precision: 0.6156\n",
      "Recall: 0.6157\n",
      "F1: 0.6155\n",
      "[[1942 1104]\n",
      " [1202 1752]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YANGZH~1\\AppData\\Local\\Temp/ipykernel_23284/1914220389.py:36: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox\" which is no longer supported as of 3.3 and will become an error in 3.6\n",
      "  plt.savefig('destree_mat_wv.pdf',dpi=300,bbox='tight')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 以熵作为不纯度度量标准\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 10, random_state = 0)\n",
    "tree.fit(X_train, Y_train)\n",
    "# 打印训练集精确度\n",
    "print('Training accuracy:', tree.score(X_train, Y_train))\n",
    "# 打印测试集精确度\n",
    "print('Test accuracy:', tree.score(X_test, Y_test))\n",
    "# 获取模型的准确率和召回率\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "y_pred = tree.predict(X_test)\n",
    "# 准确率\n",
    "print('Precision: %.4f' % precision_score(y_true=Y_test, y_pred=y_pred,average='weighted'))\n",
    "# 召回率\n",
    "print('Recall: %.4f' % recall_score(y_true=Y_test, y_pred=y_pred,average='weighted'))\n",
    "# F1\n",
    "print('F1: %.4f' % f1_score(y_true=Y_test, y_pred=y_pred,average='weighted'))\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = tree.predict(X_test)\n",
    "confmat = confusion_matrix(y_true=Y_test, y_pred=y_pred)\n",
    "print(confmat)\n",
    "# 将混淆矩阵可视化\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center',fontsize=15)\n",
    "\n",
    "plt.xlabel('预测类标',fontsize=14)\n",
    "plt.ylabel('真实类标',fontsize=14)\n",
    "plt.savefig('destree_mat_wv.pdf',dpi=300,bbox='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e9bfe36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d91b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17794251441955566 s\n",
      "0.07998394966125488\n",
      "bnb模型训练集分数: 0.6229285714285714\n",
      "bnb模型测试集分数: 0.623\n",
      "----------------------------------------\n",
      "gnb模型训练集分数: 0.5053571428571428\n",
      "gnb模型测试集分数: 0.4891666666666667\n"
     ]
    }
   ],
   "source": [
    "# 贝叶斯\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score # 交叉验证\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 模型实例化\n",
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB()\n",
    "gnb = GaussianNB()\n",
    "# 使用默认参数\n",
    "\n",
    "# 训练模型\n",
    "T1 = time.time()\n",
    "bnb.fit(X_train,y_train)\n",
    "T2 = time.time()\n",
    "print(T2-T1,'s')\n",
    "\n",
    "T1 = time.time()\n",
    "gnb.fit(X_train,y_train)\n",
    "T2 = time.time()\n",
    "print(T2-T1)\n",
    "\n",
    "# 评估模型\n",
    "# 分别看一下三个模型,在训练集和测试集的分数\n",
    "print('bnb模型训练集分数:',bnb.score(X_train,y_train))\n",
    "print('bnb模型测试集分数:',bnb.score(X_test,y_test))\n",
    "\n",
    "print('-'*40)\n",
    "print('gnb模型训练集分数:',gnb.score(X_train,y_train))\n",
    "print('gnb模型测试集分数:',gnb.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb98981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f71a4b4",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/peiwang245/article/details/82193702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "393ca617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.7361111111111112, 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "from sklearn.linear_model import LogisticRegression as LR         \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV  # 网格搜索\n",
    "\n",
    "# 把整体数据集进行切分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 40)\n",
    "#在l2范式下，判断C和solver的最优值\n",
    "p = {\n",
    "    'C':list(np.linspace(0.05,1,19)),\n",
    "    'solver':['liblinear','sag','newton-cg','lbfgs']}\n",
    "\n",
    "model = LR(penalty='l2',max_iter=1000)\n",
    "GS = GridSearchCV(model,p,cv=5)\n",
    "GS.fit(X_train,y_train)\n",
    "#输出最优参数\n",
    "GS.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a72e329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.00629925727844\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "from sklearn.linear_model import LogisticRegression        \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# 把整体数据集进行切分\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state = 40)\n",
    "\n",
    "# 用最优参数训练\n",
    "log_model = LogisticRegression(penalty='l2',C=0.736,multi_class=\"multinomial\", solver=\"newton-cg\", max_iter=1000)\n",
    "T1=time.time()\n",
    "log_model.fit(X_train,Y_train)\n",
    "T2=time.time()\n",
    "print(T2-T1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7829eff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6563333333333333 0.6579959854280639\n",
      "精确率为： 0.6811578860054509\n",
      "召回率为： 0.6563333333333333\n",
      "F1值为： 0.6563333333333333\n",
      "Cohen’s Kappa系数为： 0.31492588884655937\n"
     ]
    }
   ],
   "source": [
    "#逻辑回归评价\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.metrics import accuracy_score,precision_score, \\\n",
    "recall_score,f1_score,cohen_kappa_score\n",
    "pred_test = log_model.predict(X_test)\n",
    "acu = accuracy_score(Y_test, pred_test)  # 准确率\n",
    "recall = recall_score(Y_test, pred_test, average=\"macro\")  # 召回率\n",
    "print(acu,recall)\n",
    "\n",
    "print('精确率为：',\n",
    "      precision_score(Y_test,pred_test,average='weighted'))\n",
    "print('召回率为：',\n",
    "      recall_score(Y_test,pred_test,average='weighted'))\n",
    "print('F1值为：',\n",
    "      f1_score(Y_test,pred_test,average='micro'))\n",
    "print('Cohen’s Kappa系数为：',\n",
    "      cohen_kappa_score(Y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b08b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(multi_class  solver   \n",
       " multinomial  lbfgs        0.655433\n",
       "              newton-cg    0.674467\n",
       "              sag          0.643000\n",
       "              saga         0.642233\n",
       " ovr          lbfgs        0.649033\n",
       "              liblinear    0.659033\n",
       "              newton-cg    0.659133\n",
       "              sag          0.642267\n",
       "              saga         0.641000\n",
       " Name: acu, dtype: float64,\n",
       " multi_class  solver   \n",
       " multinomial  lbfgs        0.655579\n",
       "              newton-cg    0.674596\n",
       "              sag          0.643135\n",
       "              saga         0.642363\n",
       " ovr          lbfgs        0.649162\n",
       "              liblinear    0.659157\n",
       "              newton-cg    0.659257\n",
       "              sag          0.642397\n",
       "              saga         0.641150\n",
       " Name: recall, dtype: float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log(x_train, y_train, x_test, y_test, multi_class, solver):  # multi_class: {ovr','multinomial'}, solver: {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}\n",
    "    log_model = LogisticRegression(multi_class=multi_class, solver=solver, max_iter=1000)\n",
    "    log_model.fit(x_train,y_train)\n",
    "    pred_test = log_model.predict(x_test)\n",
    "    acu = accuracy_score(y_test, pred_test)\n",
    "    recall = recall_score(y_test, pred_test, average=\"macro\")\n",
    "    return acu, recall\n",
    "\n",
    "def run_log_reg(times, test_size):\n",
    "    result = {\"times\":[],\n",
    "              \"multi_class\":[],\n",
    "              \"solver\":[],\n",
    "              \"acu\":[],\n",
    "              \"recall\":[]}\n",
    "    for i in range(times):\n",
    "        x_train, x_test, y_train, y_test =train_test_split(X, y, test_size=test_size)\n",
    "        for multi_class in ['ovr','multinomial']:\n",
    "            for solver in ['newton-cg', 'liblinear', 'lbfgs', 'sag', 'saga']:\n",
    "                if (multi_class == 'multinomial' and solver == 'liblinear'):\n",
    "                    continue\n",
    "                acu, recall = log(x_train, y_train, x_test, y_test, multi_class, solver)\n",
    "                result[\"times\"].append(i)\n",
    "                result[\"multi_class\"].append(multi_class)\n",
    "                result[\"solver\"].append(solver)\n",
    "                result[\"acu\"].append(acu)\n",
    "                result[\"recall\"].append(recall)\n",
    "    df_re =  pd.DataFrame(result)\n",
    "    ave_acu = df_re.groupby([\"multi_class\", \"solver\"])[\"acu\"].mean()\n",
    "    ave_recall = df_re.groupby([\"multi_class\", \"solver\"])[\"recall\"].mean()\n",
    "    return ave_acu, ave_recall\n",
    "run_log_reg(5,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75178eb0",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/qq_51205385/article/details/127785470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42b6f44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0070149898529052734\n",
      "Accuracy: 0.6726666666666666\n",
      "MSE: 0.3273333333333333\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 创建分类器\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# 把整体数据集进行切分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 40)\n",
    "\n",
    "# 训练数据\n",
    "T1 = time.time()\n",
    "clf.fit(X_train,y_train)\n",
    "T2 = time.time()\n",
    "print(T2-T1)\n",
    "\n",
    "# 测试数据\n",
    "test_predictions = clf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, test_predictions))\n",
    "print('MSE:', mean_squared_error(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0f3ba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为： 0.6563333333333333\n",
      "精确率为： 0.6811578860054509\n",
      "召回率为： 0.6563333333333333\n",
      "F1值为： 0.6563333333333333\n",
      "Cohen’s Kappa系数为： 0.31492588884655937\n"
     ]
    }
   ],
   "source": [
    "print('准确率为：', \n",
    "      accuracy_score(Y_test,pred_test)) \n",
    "print('精确率为：',\n",
    "      precision_score(Y_test,pred_test,average='weighted'))\n",
    "print('召回率为：',\n",
    "      recall_score(Y_test,pred_test,average='weighted'))\n",
    "print('F1值为：',\n",
    "      f1_score(Y_test,pred_test,average='micro'))\n",
    "print('Cohen’s Kappa系数为：',\n",
    "      cohen_kappa_score(Y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17544e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f422e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
