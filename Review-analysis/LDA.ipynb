{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ae1da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "西安/兵马俑/"
     ]
    }
   ],
   "source": [
    "stop_word = pd.read_csv('停用词.csv',names=['w'],sep='\\t',encoding='utf-8')\n",
    "l=[w for w in jieba.cut('西安兵马俑') if w not in list(stop_word.w)]\n",
    "for i in l:\n",
    "    print(i,end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b084cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "值得     8521\n",
       "西安     6951\n",
       "历史     6130\n",
       "导游     5343\n",
       "城墙     4321\n",
       "兵马俑    3525\n",
       "博物馆    2967\n",
       "景色     2958\n",
       "震撼     2766\n",
       "小时     2626\n",
       "华山     2607\n",
       "排队     2350\n",
       "携程     2255\n",
       "风景     2234\n",
       "感受     2124\n",
       "晚上     2120\n",
       "体验     2119\n",
       "坐      2099\n",
       "表演     2090\n",
       "喜欢     2043\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "gp = open(\"评论文本.txt\",encoding='utf-8').read()\n",
    "gp = gp.replace('\\n','')\n",
    "gp = gp.replace(' ','')\n",
    "word_list = [w for w in jieba.cut(gp) if w not in list(stop_word.w)] # 去除停用词\n",
    "\n",
    "# 转为数据框，方便统计词频\n",
    "df = pd.DataFrame(word_list, columns = ['word'])\n",
    "#df.head()\n",
    "\n",
    "result = df.groupby(['word']).size()\n",
    "# print(result)\n",
    "freqlist = result.sort_values(ascending=False) # 降序\n",
    "freqlist[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e52bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
      "                          max_iter=50, n_components=5, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "# 指定 lda 主题数\n",
    "n_topics = 5\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics, max_iter=50,\n",
    "    learning_method='online',\n",
    "    learning_offset=50.,\n",
    "    random_state=0)\n",
    "print(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cdd2dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>遇</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>好人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>强</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>汉中</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>西安</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>院是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>迈出</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>之西峻险</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>挺秀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>称雄</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word\n",
       "0         遇\n",
       "1        好人\n",
       "2         强\n",
       "3        汉中\n",
       "4        西安\n",
       "...     ...\n",
       "29995    院是\n",
       "29996    迈出\n",
       "29997  之西峻险\n",
       "29998    挺秀\n",
       "29999    称雄\n",
       "\n",
       "[30000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去重、去缺失、分词\n",
    "df1=df.drop_duplicates().reset_index().drop('index',axis=1)\n",
    "df2=df1.iloc[:30000,:]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06512b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          max_iter=50, n_components=5, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 构造 TF-IDF\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "tf_idf = tf_idf_vectorizer.fit_transform(df2.word)\n",
    "# 特征词列表\n",
    "feature_names = tf_idf_vectorizer.get_feature_names()\n",
    "# 特征词 TF-IDF 矩阵\n",
    "matrix = tf_idf.toarray()\n",
    "# 指定 lda 主题数\n",
    "n_topics = 5\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics, max_iter=50,\n",
    "    learning_method='online',\n",
    "    learning_offset=50.,\n",
    "    random_state=0)\n",
    "# 核心，给 LDA 喂生成的 TF-IDF 矩阵\n",
    "lda.fit(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595b3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def top_words_data_frame(model: LatentDirichletAllocation,\n",
    "                         tf_idf_vectorizer: TfidfVectorizer,\n",
    "                         n_top_words: int) -> pd.DataFrame:\n",
    "    '''\n",
    "    求出每个主题的前 n_top_words 个词\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn 的 LatentDirichletAllocation \n",
    "    tf_idf_vectorizer : sklearn 的 TfidfVectorizer\n",
    "    n_top_words :前 n_top_words 个主题词\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: 包含主题词分布情况\n",
    "    '''\n",
    "    rows = []\n",
    "    feature_names = tf_idf_vectorizer.get_feature_names()\n",
    "    for topic in model.components_:\n",
    "        top_words = [feature_names[i]\n",
    "                     for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        rows.append(top_words)\n",
    "    columns = [f'topic {i+1}' for i in range(n_top_words)]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def predict_to_data_frame(model: LatentDirichletAllocation, X: np.ndarray) -> pd.DataFrame:\n",
    "    '''\n",
    "    求出文档主题概率分布情况\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn 的 LatentDirichletAllocation \n",
    "    X : 词向量矩阵\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: 包含主题词分布情况\n",
    "    '''\n",
    "    # 求出给定文档的主题概率分布矩阵\n",
    "    matrix = model.transform(X)\n",
    "    columns = [f'P(topic {i+1})' for i in range(len(model.components_))]\n",
    "    df = pd.DataFrame(matrix, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0689ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 本地 csv 文件，可以是本地文件，也可以是远程文件\n",
    "source_csv_path = 'answers.csv'\n",
    "# 文本 csv 文件里面文本所处的列名,注意这里一定要填对，要不然会报错的！\n",
    "document_column_name = '回答内容'\n",
    "# 输出主题词的文件路径\n",
    "top_words_csv_path = 'top-topic-words.csv'\n",
    "# 输出各文档所属主题的文件路径\n",
    "predict_topic_csv_path = 'document-distribution.csv'\n",
    "# 可视化 html 文件路径\n",
    "html_path = 'document-lda-visualization.html'\n",
    "# 选定的主题数\n",
    "n_topics = 5\n",
    "# 要输出的每个主题的前 n_top_words 个主题词数\n",
    "n_top_words = 20\n",
    "\n",
    "# 计算 n_top_words 个主题词\n",
    "top_words_df = top_words_data_frame(lda, tf_idf_vectorizer, n_top_words)\n",
    "\n",
    "# 保存 n_top_words 个主题词到 csv 文件中\n",
    "top_words_df.to_csv(top_words_csv_path, encoding='utf-8-sig', index=None)\n",
    "\n",
    "# 转 tf_idf 为数组，以便后面使用它来对文本主题概率分布进行计算\n",
    "X = tf_idf.toarray()\n",
    "\n",
    "# 计算完毕主题概率分布情况\n",
    "predict_df = predict_to_data_frame(lda, X)\n",
    "\n",
    "# 保存文本主题概率分布到 csv 文件中\n",
    "predict_df.to_csv(predict_topic_csv_path, encoding='utf-8-sig', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f72506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36db0ee4",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/403058948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b66e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
